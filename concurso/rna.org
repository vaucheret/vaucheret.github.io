#+TITLE: [[size:65%][Sistemas Inteligentes]]
#+AUTHOR: Redes Neuronales Artificiales
#+DATE:  Claudio Vaucheret
#+EMAIL: cv@fi.uncoma.edu.ar


#+REVEAL_INIT_OPTIONS:  transition:'slide' 
#+options: toc:nil num:nil

#+REVEAL_THEME: sky
#+REVEAL_HLEVEL: 2
#+reveal_root:  https://cdn.jsdelivr.net/npm/reveal.js
#+REVEAL_EXTRA_CSS: grids.css

* Introducción

** ¿Qué vimos?
#+REVEAL_HTML: <div style="font-size: 80%;">   
    - Clases de Aprendizaje
      - Supervisado
	- Árboles de decisión
	- SVM
	- Evaluación de los Modelos
      - No Supervisado
	- Clustering
        - K-means
	- Clustering Jerárquico
	- Evaluación de los Modelos
      - Por refuerzo

#+REVEAL_HTML: <div style="font-size: 120%;">   	
#+ATTR_REVEAL: :frag (roll-in)
  - [[color:red][Hoy:   Redes Neuronales Artificiales]]
 #+REVEAL_HTML: </div>
  #+REVEAL_HTML: </div>

** Inteligencia Artificial
#+REVEAL_HTML: <div style="font-size: 75%;">
    - *Simbólica*: [[color:blue][Hipótesis del sistema de símbolos físicos]]
       - [[color:orange][Allen Newell y Herbert Simon]].
    - *Subsimbólica*:
      - [[color:green][/Modelos Emergentes/]]
	- basados en la evolución, las soluciones potenciales
          compiten y evolucionan.
	- Propiedades: masivamente paralelos, comportamiento complejo evoluciona a partir de comportamiento simple.
	- Ejemplo: algoritmos genéticos, vida artificial.
      - [[color:green][/Modelos Conexionistas/]]
	- basados en el cerebro, modela neuronas individuales y sus conexiones.
	- Propiedades: paralelos y distribuidos.
	- Ejemplo: [[color:red][redes neuronales]]
 #+REVEAL_HTML: </div>

* Historia

** Inicios
#+REVEAL_HTML: <div style="font-size: 60%;">   
 #+REVEAL_HTML: <div class="gridded_frame_with_columns">
 #+REVEAL_HTML: <div class="one_of_2_columns"> 

#+ATTR_HTML: :height 300 :align center
[[file:imagenes/wsmcculloch.jpg]]

 Warren Sturgis McCulloch (1898-1969)
 Neurólogo e Informático Estadounidense
 #+REVEAL_HTML: </div>
 #+REVEAL_HTML: <div class="one_of_2_columns"> 
#+ATTR_HTML: :height 300 :align center
[[file:imagenes/walterPitts-2.jpg]] 
 
 Walter Harry Pitts
(1923 - 1969)
Lógico estadounidense que trabajó en el campo de neurociencia computacional.
  #+REVEAL_HTML: </div>
  #+REVEAL_HTML: </div>
  [[color:brown][*1943:*]] Escriben un trabajo en el que describen el primer modelo
   matemático para una red neuronal.
  #+REVEAL_HTML: </div>

*** Hitos
#+REVEAL_HTML: <div style="font-size: 80%;">
#+ATTR_REVEAL: :frag (roll-in)
- [[color:green][*1943-1949*]] Nacimiento teórico de las Redes Neuronales Artificiales - McCulloch & Pitts (1943), Hebb (1949)
- [[color:green][*1950's & 1960's*]] Desarrollo optimista  Minsky (50's), Rosenblatt (60's)
- [[color:green][*1970's*]] Minsky & Papert muestran serias limitaciones
- [[color:green][*1980's & 1990's*]] Renacimiento: nuevos modelos y técnicas, Backpropagation, Hopfield, redes recurrentes
- [[color:green][*2012*]] Aprendizaje en Profundidad, Redes Convolucionales,
- [[color:green][*2014*]] Redes Generativas Adversarias.
- [[color:green][*2017-*]] Transformers y Procesamiento de Lenguaje Natural, Atencion.
 #+REVEAL_HTML: </div>

  
*** Perceptron vs Multi Capa


[[file:imagenes/percp.webp]]


  
* Motivación

** De dónde surgió la idea

[[file:imagenes/brain-and-happiness.jpg]]

 El cerebro tiene 100.000 millones de neuronas.

 
*** Neurona Natural

[[file:imagenes/neurona.png]]

#+REVEAL: split


	- Las [[color:red][dendritas]] recogen la señales de otras neuronas
	- El [[color:red][Soma]] Procesa la información
	- Los [[color:red][axones]] envían señales a otras neuronas
	- las [[color:red][sinapsis]] son los puntos de conexión a otras neuronas

#+REVEAL: split
#+REVEAL_HTML: <div style="font-size: 80%;">
 #+REVEAL_HTML: <div class="gridded_frame_with_columns">
 #+REVEAL_HTML: <div class="one_of_2_columns"> 
[[file:imagenes/potencial.png]]

- Finalmente, si debe existir respuesta, se excitan neuronas eferentes que controlan músculos, glándulas u otras estructuras anatómicas. 


 #+REVEAL_HTML: </div>
 #+REVEAL_HTML: <div class="one_of_2_columns"> 


	- La señal se inicia cuando una neurona sensorial recibe un estímulo externo. Su axón se denomina fibra aferente.
	- Esta neurona sensorial transmite una señal a otra aledaña, de modo que acceda un centro de integración del sistema nervioso.
	- Las interneuronas, situadas en dicho sistema, transportan la señal a través de sinapsis.

 #+REVEAL_HTML: </div>
 #+REVEAL_HTML: </div>
 #+REVEAL_HTML: </div>
  
* Neuronas Artificiales


** Neurona de McCulloch y Pitts

[[file:imagenes/pills.png]]

#+REVEAL: split

Para $n$ entradas $(x_1,x_2,\ldots,x_j,\ldots,x_n)$

$$z = b + \sum_{i=1}^{n}w_ix_i$$ 

$$ a = f(z) \left\{ \begin{array}{ll} 1    &  z \ge 0 \\  0  &  z < 0  \end{array}  \right. $$

o sea en su definición mas simple con dos entradas

$$ a =  \left\{ \begin{array}{ll} 1    &  \mathrm{si\ } b + w_1x_1 + w_2x_2  \ge 0 \\  0  &  \mathrm{si\ } b + w_1x_1 + w_2x_2 < 0  \end{array}  \right. $$

#+REVEAL: split

siendo $b + w_1x_1 + w_2x_2 = 0$ una recta que define la frontera de la decisión.


#+ATTR_REVEAL: :frag (roll-in)
Supongamos $w_1 = -1$ , $w_2 = 2$  y $b = 0$ tenemos la recta $-x_1 + 2x_2 = 0$

#+ATTR_REVEAL: :frag (roll-in)
[[file:imagenes/frontera1.png]]

#+REVEAL: split

¿Qué ocurre cuando $b \not= 0$?

$$ W^T \times X + b = \left[ \begin{matrix} -1 & 2 \end{matrix} \right] \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] + b =  -x_1 + 2x_2 + b = 0$$

#+ATTR_REVEAL: :frag (roll-in)
[[file:imagenes/frontera2.png]]

*** Resumiendo

	- Frontera de Decisión: Una neurona perceptrón divide al espacio  de entrada  en dos para clasificar patrones.
	- $W$, los pesos sinápticos controlan la orientación de la Frontera de Decisión.
	-  El  umbral o polarización  $b$ controla la traslación de la Frontera de Decisión.




*** Ejemplo
#+REVEAL_HTML: <div style="font-size: 80%;">
Supongamos que queremos clasificar ananás y manzanas y que disponemos
de dos atributos: peso y color promedio.

| $x_1$ = Peso | $x_2$ = Color | Clasificación | Salida de la Neurona |
|--------------+---------------+---------------+----------------------|
|          1.5 |          -0.3 | [[color:red][ananá]]         |                   -1 |
|          0.9 |          0.05 | [[color:red][ananá]]         |                   -1 |
|          2.1 |           0.2 | [[color:red][ananá]]         |                   -1 |
|         0.24 |         -0.87 | [[color:blue][manzana]]       |                    1 |
|         0.45 |          -0.6 | [[color:blue][manzana]]       |                    1 |
|         0.15 |         -0.43 | [[color:blue][manzana]]       |                    1 |
|--------------+---------------+---------------+----------------------|
 #+REVEAL_HTML: </div>
#+REVEAL: split

[[file:imagenes/ejemplo1t.png]]

[[color:red][Rojo]] = ananá y [[color:blue][Azul]] = manzana 

¿Cuáles serían posibles valores para los pesos  sinápticos y el umbral?

#+REVEAL: split

Elegimos [[color:brown][$-x_1 - x_2 + 0.5=0$]]

[[file:imagenes/ejemplo2t.png]]

#+ATTR_REVEAL: :frag (roll-in)
#+REVEAL_HTML: <div style="font-size: 90%;">
Voilá!!! Obtuvimos los pesos sinápticos y el umbral.
$$\mathbf{w}=\Bigg[ \begin{matrix}-1 \\ -1 \end{matrix}\Bigg] \ \ \ b=0.5 $$
 #+REVEAL_HTML: </div>

** Perceptrón

[[file:imagenes/pills.png]]

*** Función de activación

#+ATTR_HTML: :height 300 :align center
[[file:imagenes/escalon.png]]

$$  f(n) =  \left\{ \begin{array}{ll} 1    &  n \ge 0 \\  0  &  n < 0  \end{array}  \right. $$


*** Entrenamiento

sea $(x^1,y^1),\ldots,(x^r,y^r),\ldots,(x^N,y^N)$ un conjunto de entrenamiento

se ajustan los pesos con la *regla de Hebb*:

$$w_i(t + 1) = w_i(t) + \eta\sum_{r=1}^{N}(y^r - a^r)x_i^r$$

$$b(t + 1) = b(t) + \eta\sum_{r=1}^{N}(y^r - a^r)$$


*** Expresividad

[[file:imagenes/xorandnot.png]]

** Modelo Bicapa
 #+REVEAL_HTML: <div class="gridded_frame_with_columns">
 #+REVEAL_HTML: <div class="one_of_2_columns"> 
#+ATTR_HTML: :height 300 :align center
[[file:imagenes/bicapan.png]]

 #+REVEAL_HTML: </div>
 #+REVEAL_HTML: <div class="one_of_2_columns"> 
#+REVEAL_HTML: <div style="font-size: 80%;">


Rosenblatt en [[color:orange][1958]] introdujo el perceptrón simple formado por dos capas, una de entrada con [[color:orange][$n$]] neuronas y una de salida con [[color:orange][$m$]] neuronas.

#+REVEAL_HTML: </div>
  #+REVEAL_HTML: </div>
  #+REVEAL_HTML: </div>

#+REVEAL: split

$$z_i = b_i + \sum_{j=1}^{n}w_{ij}x_j (i = 1\ldots m)$$

$$a_i = f(z_i)$$

la variable objetivo $y^r$, donde $r = 1\ldots N$ se convierte en un vector de $m$ posiciones.

$$y^r = (y^r_i) \mathrm{\  con \ } i = 1\ldots m$$
 
*** Función de activación
 #+REVEAL_HTML: <div class="gridded_frame_with_columns">
 #+REVEAL_HTML: <div class="one_of_2_columns"> 
#+REVEAL_HTML: <div style="font-size: 80%;">

$$f(z)=\sigma(z)= \frac{1}{1+ e^{-z}}$$

su derivada es muy simple:

$$y^\prime = \frac{dy}{dx}=\frac{e^{-x}}{(1+e^{-x})^2}$$
  #+REVEAL_HTML: </div>
  #+REVEAL_HTML: </div>

 #+REVEAL_HTML: <div class="one_of_2_columns">   
#+ATTR_HTML: :height 300 :align center
[[file:imagenes/FuncionSigmoide.png]]

#+REVEAL_HTML: </div>
 #+REVEAL_HTML: </div>


*** Entrenamiento

#+REVEAL_HTML: <div style="font-size: 80%;">
se basa en minimizar la función de errores al cuadrado por el
procedimiento iterativo de gradiente de descenso. Donde la función de
errores al cuadrado es:
#+REVEAL_HTML: </div>

$$C(b_i,w_{ij}) = \frac{1}{2} \sum_{r=1}^{N}(a_i^r - y_i^r)²  (i = 1 \ldots m)$$

$$C(b_i,w_{ij}) = \frac{1}{2} \sum_{r=1}^{N}\left(\sigma\left(b_i + \sum_{j=1}^{n}w_{ij}x_j^r \right) - y_i^r\right)^2  (i = 1 \ldots m)$$


#+REVEAL: split
#+REVEAL_HTML: <div style="font-size: 80%;">
se sabe que el vector gradiente :
#+REVEAL_HTML: </div>

$$\Delta C(b_i,w_i) = (\frac{\partial C}{\partial b_i}, \frac{\partial C}{\partial w_{i1}},\ldots,\frac{\partial C}{\partial w_{in}})$$

#+REVEAL_HTML: <div style="font-size: 80%;">
va en la dirección del mayor incremento de $C$ en el punto del dominio $(b_i,w_i)$.
 para ir en el sentido del mayor decremento del error cuadrático se toma el valor negativo $- \Delta C(b_i,w_i)$
 el factor de aprendizaje $\eta$ determina el tamaño del salto.
#+REVEAL_HTML: </div>

$$(b_i,w_i)[t+1] = (b_i,w_i)[t]- \eta \Delta C(b_i,w_i)$$


#+REVEAL: split

#+ATTR_HTML: :height 350 :align center
[[file:imagenes/gradiente-descenso.png]]
#+REVEAL_HTML: <div style="font-size: 80%;">
$$\frac{\partial C}{\partial w_{ij}} = \sum_{r=1}^{N}(a_i^r - y_i^r) \sigma'(z_i^r)x_j^r \mathrm{\ \ \ \ \  } i=1\ldots m$$

$$\frac{\partial C}{\partial b_i} = \sum_{r=1}^{N}(a_i^r - y_i^r) \sigma'(z_i^r) \mathrm{\ \ \ \ \  } i=1\ldots m$$
#+REVEAL_HTML: </div>
*** Resolución matricial



#+ATTR_HTML: :height 400 :align center
[[file:imagenes/Neurona-2Capas.png]]

#+REVEAL: split

#+REVEAL_HTML: <div style="font-size: 80%;">
Dada dada una matriz $X$ de $N$ registros que entran a la neurona y dados
 unos pesos y bias definidos en las matrices $W$ y $B$, se tendrá la
 siguiente salida de forma matricial:
#+REVEAL_HTML: </div>

$$Z = B^T \oplus X \cdot W^T$$ y

$$A = \sigma (Z)$$

#+REVEAL_HTML: <div style="font-size: 80%;">
El error neto entre los valores reales $Y$ y los activados:
#+REVEAL_HTML: </div>

$$A - Y$$

#+REVEAL: split

#+REVEAL_HTML: <div style="font-size: 80%;">
La tasa de variación del error cuadrático por unidad de entrada, que
es la parte común de los dos gradientes anteriores, se puede poner
matricialmente mediante la matriz $\Delta$ :
#+REVEAL_HTML: </div>

$$\Delta = (A - Y) \odot \sigma'(Z)$$

#+REVEAL_HTML: <div style="font-size: 80%;">
se utiliza el producto de Hadamard $(s \odot t)$, que aplicado a dos
matrices o vectores, es el producto de sus elementos término a término
#+REVEAL_HTML: </div>

#+REVEAL: split

#+REVEAL_HTML: <div style="font-size: 80%;">
finalmente, el entrenamiento en $T$ etapas, partiendo de valores aleatorios en las matrices $W$ y $B$ en $t=1$, de forma que en sucesivos $t$:

#+REVEAL_HTML: </div>
$$W(t + 1) = W(t) - \eta \Delta^T \cdot X$$

$$B(t + 1) = B(t) - \eta \Delta^T \cdot \mathbf{1}$$

** [[size:80%][Modelo Multicapa]]

#+ATTR_HTML: :height 400 :align center
[[file:imagenes/RedMultiCapa.png]]

#+REVEAL_HTML: <div style="font-size: 70%;">
La función de coste del error en la  última capa $L$ es:

$$C = \frac{1}{2} \sum_x \| a^L - y \|^2  \ \ \ \ \ \ \ \ \ \ \ \frac{\partial C}{\partial w_{jk}^l};\frac{\partial C}{\partial b_j^l}$$
#+REVEAL_HTML: </div>

*** Retropropagación

#+REVEAL_HTML: <div style="font-size: 80%;">
El algoritmo de retropropagación que permite entrenar una red
multicapa se introduce en 1970, pero no es hasta 1986 con el artículo
de Rumelhart, 1986 cuando se aprecia su potencial
#+REVEAL_HTML: </div>

# #+ATTR_HTML: :height 200 :align center
# [[file:imagenes/RedTriCapa.png]]



#+REVEAL: split

Proceso hacia Adelante o  Forward,

Para la capa $1 \le l \le L$:

$$A^l = \sigma((B^l)^T \oplus A^{l-1} \cdot (W^l)^T) = \sigma(Z^l)$$

si $l = 1$ entonces $A^{l-1} = X$

#+REVEAL: split

Luego calculamos el error en la última capa

$$E = Y - A^L$$

La tasa de variación del error cuadrático por unidad de activación en la última capa $L$ es:

$$\Delta^L = (Y - A^L) \odot \sigma'(Z^L)$$

#+REVEAL: split

Luego calculamos la variación del error cuadrático en cada capa $l$ desde $L - 1$ hasta $1$:
(Retropropagación)


$$\Delta^L = (\Delta^{l + 1} \cdot W^{l + 1}) \odot \sigma'(Z^L)$$

#+REVEAL: split

Finalmente entrenamos la red, con del descenso del gradiente.

$$W^l(t + 1) = W^l(t) - \eta(\Delta^l)^T \cdot A^{l - 1}$$

$$B^l(t + 1) = B^l(t) - \eta(\Delta^l)^T \cdot \mathbf{1}$$

siendo $\mathbf{1}$ una matriz columna de $N$ unos que realiza la sumatoria de las filas de $\Delta^T$

Ademas si $l = 1$

$$A^{l-1} = X$$


** [[size:70%][Otras Funciones de Activación]]

 #+REVEAL_HTML: <div class="gridded_frame_with_columns">
 #+REVEAL_HTML: <div class="one_of_2_columns"> 

#+ATTR_HTML: :height 400 :align center
[[file:imagenes/factivacion.png]]


  #+REVEAL_HTML: </div>

 #+REVEAL_HTML: <div class="one_of_2_columns">   

#+REVEAL_HTML: <div style="font-size: 50%;">
 - *La función tangente hiperbólica  (muy similar a la sigmoidea)*:

   Satura y anula el gradiente. Lenta convergencia. Centrada
   en 0. Esta acotada entre -1 y 1. Se utiliza para clasificaciones
   binarias. Buen desempeño en redes recurrentes (que se utilizan para
   analizar series temporales).

 - *La función ReLU (Rectified Lineal Unit)*:

   Solo se activa si son positivos. No está acotada. Puede anular
   demasiadas neuronas. Se comporta bien con imágenes. Buen desempeño
   en redes convolucionales
   #+REVEAL_HTML: </div>
  #+REVEAL_HTML: </div>
    #+REVEAL_HTML: </div>

    
** Overfitting

[[file:imagenes/overfittingc.png]]

#+ATTR_HTML: :height 300 :align center
[[file:imagenes/sobreajuste.png]]

** PlayGround

https://playground.tensorflow.org/

